{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4FoJTkphioq/hbwz9215l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thompson005/Rejen_thompson/blob/main/keyword.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install sentence-transformers\n",
        "!pip install qdrant-client\n",
        "!pip install requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUysbWWalmzo",
        "outputId": "7950b99b-ddf2-4f2d-c2bf-30a6c6981dca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/171.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m163.8/171.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 sentence-transformers-2.7.0\n",
            "Collecting qdrant-client\n",
            "  Downloading qdrant_client-1.9.1-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.3/229.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.63.0)\n",
            "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
            "  Downloading grpcio_tools-1.63.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx[http2]>=0.20.0 (from qdrant-client)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.25.2)\n",
            "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pydantic>=1.10.8 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.7.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.0.7)\n",
            "Collecting protobuf<6.0dev,>=5.26.1 (from grpcio-tools>=1.41.0->qdrant-client)\n",
            "  Downloading protobuf-5.26.1-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (67.7.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10.8->qdrant-client) (4.11.0)\n",
            "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx[http2]>=0.20.0->qdrant-client) (1.2.1)\n",
            "Installing collected packages: protobuf, portalocker, hyperframe, hpack, h11, httpcore, h2, grpcio-tools, httpx, qdrant-client\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-api-core 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-aiplatform 1.51.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.25.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-datastore 2.15.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-firestore 2.11.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-functions 1.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-iam 2.15.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-language 2.13.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "google-cloud-translate 3.11.3 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "googleapis-common-protos 1.63.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0.dev0,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 5.26.1 which is incompatible.\n",
            "proto-plus 1.23.0 requires protobuf<5.0.0dev,>=3.19.0, but you have protobuf 5.26.1 which is incompatible.\n",
            "tensorflow 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.26.1 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.26.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed grpcio-tools-1.63.0 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hyperframe-6.0.1 portalocker-2.8.2 protobuf-5.26.1 qdrant-client-1.9.1\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWMHoRgck_no",
        "outputId": "21be25c1-e98d-4069-e57f-59ed187333e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter keyword to search: data_export_01\n",
            "Found 10 document(s) matching the keyword 'data_export_01':\n",
            "Document ID: c8e992a2-1f3d-4288-ab41-879cf787dd40\n",
            "Filename: 10.json\n",
            "Date: 2024-02-18\n",
            "Source: CSV\n",
            "Category: hr_data\n",
            "File Content: \n",
            "==================================================\n",
            "Document ID: a1c02990-3253-41a4-83fc-3b9444d726b4\n",
            "Filename: 10.json\n",
            "Date: 2024-02-18\n",
            "Source: CSV\n",
            "Category: hr_data\n",
            "File Content: Employee records updated in February 2024.\n",
            "==================================================\n",
            "Document ID: 3a9e2584-a396-42a9-bf5f-09e177bfc4bf\n",
            "Filename: 10.json\n",
            "Date: 2024-02-18\n",
            "Source: CSV\n",
            "Category: hr_data\n",
            "File Content: Employee records updated in February 2024.\n",
            "==================================================\n",
            "Document ID: c0a12e17-fb5d-4280-b6f5-2bf1a5fa8003\n",
            "Filename: 5.json\n",
            "Date: 2024-04-05\n",
            "Source: API\n",
            "Category: feedback_data\n",
            "File Content: Customer feedback collected from the mobile app.\n",
            "==================================================\n",
            "Document ID: d6f7000e-2937-4cde-9ebe-e7a4dd0e80a3\n",
            "Filename: 5.json\n",
            "Date: 2024-04-05\n",
            "Source: API\n",
            "Category: feedback_data\n",
            "File Content: \n",
            "==================================================\n",
            "Document ID: 684627d4-fc5d-4cc4-8e30-651d2ddce09f\n",
            "Filename: 5.json\n",
            "Date: 2024-04-05\n",
            "Source: API\n",
            "Category: feedback_data\n",
            "File Content: Customer feedback collected from the mobile app.\n",
            "==================================================\n",
            "Document ID: 0c6dfed6-c363-4c0a-9a00-9b1dc1b04984\n",
            "Filename: 6.json\n",
            "Date: 2023-11-19\n",
            "Source: CSV\n",
            "Category: inventory_data\n",
            "File Content: \n",
            "==================================================\n",
            "Document ID: c0a6a99c-0646-4b76-ba96-dc12cd2405b3\n",
            "Filename: 6.json\n",
            "Date: 2023-11-19\n",
            "Source: CSV\n",
            "Category: inventory_data\n",
            "File Content: Exported inventory list from November 2023.\n",
            "==================================================\n",
            "Document ID: 2baf32ab-7298-41d2-b0e9-816f15756709\n",
            "Filename: 6.json\n",
            "Date: 2023-11-19\n",
            "Source: CSV\n",
            "Category: inventory_data\n",
            "File Content: Exported inventory list from November 2023.\n",
            "==================================================\n",
            "Document ID: f78c46ef-edc5-458b-946f-f771fa90910f\n",
            "Filename: 2.json\n",
            "Date: 2024-01-15\n",
            "Source: Sensor\n",
            "Category: sensor_data\n",
            "File Content: \n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.exceptions import UnexpectedResponse\n",
        "\n",
        "# Initialize the model and Qdrant client\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "client = QdrantClient(url=\"https://944b11e1-daeb-46a5-9b88-a345cfe7e2ac.us-east4-0.gcp.cloud.qdrant.io\", api_key=\"SUlSIT3RCnbSEM46GLlYfniBuP6YmThoXP8u0qrW1TlV5iyUhjZ2BQ\")\n",
        "\n",
        "# Function to convert text to vector using the model\n",
        "def text_to_vector(text):\n",
        "    # Encode text to vector with SentenceTransformer\n",
        "    vector = model.encode(text)\n",
        "    # Ensure vector dimension matches Qdrant's requirement (128)\n",
        "    vector = vector[:128]  # Adjust based on the actual model output and Qdrant's requirement\n",
        "    return vector.tolist()  # Convert to list for Qdrant\n",
        "\n",
        "# Function to search for documents containing a keyword\n",
        "def search_documents_by_keyword(client, collection_name, keyword):\n",
        "    try:\n",
        "        # Convert keyword to vector\n",
        "        query_vector = text_to_vector(keyword)\n",
        "\n",
        "        # Perform vector search in Qdrant\n",
        "        hits = client.search(\n",
        "            collection_name=collection_name,\n",
        "            query_vector=query_vector,\n",
        "            limit=10  # Adjust as per your requirement to limit the number of results\n",
        "        )\n",
        "\n",
        "        # Collect documents that match the keyword\n",
        "        found_documents = []\n",
        "        for hit in hits:\n",
        "            found_documents.append(hit)\n",
        "\n",
        "        return found_documents\n",
        "\n",
        "    except UnexpectedResponse as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    keyword = input(\"Enter keyword to search: \")\n",
        "\n",
        "    try:\n",
        "        # Define the collection name\n",
        "        collection_name = \"json_files\"  # Adjust based on your actual collection name\n",
        "\n",
        "        # Search for documents containing the keyword\n",
        "        found_documents = search_documents_by_keyword(client, collection_name, keyword)\n",
        "\n",
        "        if found_documents:\n",
        "            print(f\"Found {len(found_documents)} document(s) matching the keyword '{keyword}':\")\n",
        "            for doc in found_documents:\n",
        "                print(f\"Document ID: {doc.id}\")\n",
        "                print(f\"Filename: {doc.payload.get('filename', '')}\")\n",
        "                print(f\"Date: {doc.payload.get('date', '')}\")\n",
        "                print(f\"Source: {doc.payload.get('source', '')}\")\n",
        "                print(f\"Category: {doc.payload.get('category', '')}\")\n",
        "                print(f\"File Content: {doc.payload.get('file_content', '')}\")\n",
        "                print(\"=\" * 50)\n",
        "        else:\n",
        "            print(f\"No documents found containing the keyword '{keyword}'.\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"Error: {ve}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8MSeA3pRoFAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.exceptions import UnexpectedResponse\n",
        "\n",
        "# Initialize the model and Qdrant client\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "client = QdrantClient(url=\"https://944b11e1-daeb-46a5-9b88-a345cfe7e2ac.us-east4-0.gcp.cloud.qdrant.io\", api_key=\"SUlSIT3RCnbSEM46GLlYfniBuP6YmThoXP8u0qrW1TlV5iyUhjZ2BQ\")\n",
        "\n",
        "# Function to convert text to vector using the model\n",
        "def text_to_vector(text):\n",
        "    # Encode text to vector with SentenceTransformer\n",
        "    vector = model.encode(text)\n",
        "    # Ensure vector dimension matches Qdrant's requirement (128)\n",
        "    vector = vector[:128]  # Adjust based on the actual model output and Qdrant's requirement\n",
        "    return vector.tolist()  # Convert to list for Qdrant\n",
        "\n",
        "# Function to search for documents containing a keyword\n",
        "# Function to search for documents containing a keyword\n",
        "# Function to search for documents containing a keyword\n",
        "def search_documents_by_keyword(client, collection_name, keyword):\n",
        "    try:\n",
        "        # Convert keyword to vector\n",
        "        query_vector = text_to_vector(keyword)\n",
        "\n",
        "        # Perform vector search in Qdrant\n",
        "        hits = client.search(\n",
        "            collection_name=collection_name,\n",
        "            query_vector=query_vector,\n",
        "            limit=10  # Adjust as per your requirement to limit the number of results\n",
        "        )\n",
        "\n",
        "        # Collect documents that match the keyword\n",
        "        found_documents = []\n",
        "        for hit in hits:\n",
        "            # Check if the document contains the keyword\n",
        "            file_content = hit.payload.get('file_content', '')\n",
        "            if keyword.lower() in file_content.lower():\n",
        "                found_documents.append(hit)\n",
        "            else:\n",
        "                print(f\"Keyword '{keyword}' not found in document {hit.id} content.\")\n",
        "                print(f\"Document content: {file_content}\")\n",
        "\n",
        "        return found_documents\n",
        "\n",
        "    except UnexpectedResponse as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    keyword = input(\"Enter keyword to search: \")\n",
        "\n",
        "    try:\n",
        "        # Define the collection name\n",
        "        collection_name = \"json_files\"  # Adjust based on your actual collection name\n",
        "\n",
        "        # Search for documents containing the keyword\n",
        "        found_documents = search_documents_by_keyword(client, collection_name, keyword)\n",
        "\n",
        "        if found_documents:\n",
        "            print(f\"Found {len(found_documents)} document(s) matching the keyword '{keyword}':\")\n",
        "            for doc in found_documents:\n",
        "                print(f\"Document ID: {doc.id}\")\n",
        "                print(f\"Filename: {doc.payload.get('filename', '')}\")\n",
        "                print(f\"Date: {doc.payload.get('date', '')}\")\n",
        "                print(f\"Source: {doc.payload.get('source', '')}\")\n",
        "                print(f\"Category: {doc.payload.get('category', '')}\")\n",
        "                print(f\"File Content: {doc.payload.get('file_content', '')}\")\n",
        "                print(\"=\" * 50)\n",
        "        else:\n",
        "            print(f\"No documents found containing the keyword '{keyword}'.\")\n",
        "\n",
        "    except ValueError as ve:\n",
        "        print(f\"Error: {ve}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pR5P_t-ozwO",
        "outputId": "8c990b17-d400-479e-faf8-20d08adfe69c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter keyword to search: log\n",
            "Keyword 'log' not found in document 76643a4b-294c-4fc9-902e-4e30891228fb content.\n",
            "Document content: audit report \n",
            "Keyword 'log' not found in document ec1dde1a-bf6c-4855-874f-ecbd084360a0 content.\n",
            "Document content: \n",
            "Keyword 'log' not found in document 67e9e821-01e0-4ed2-bf87-e5da0b15ab54 content.\n",
            "Document content: Quarterly sales report for Q3 2023.\n",
            "Keyword 'log' not found in document 0d98280a-e9c5-4c10-a72e-f4fb4e14b798 content.\n",
            "Document content: Quarterly sales report for Q3 2023.\n",
            "Keyword 'log' not found in document 15e7baf8-d875-4377-9be7-af06aa8c4d79 content.\n",
            "Document content: \n",
            "Keyword 'log' not found in document 1a0ea114-bc53-4bb8-9653-c4baf23396df content.\n",
            "Document content: \n",
            "Found 4 document(s) matching the keyword 'log':\n",
            "Document ID: 3da42137-8751-4747-8aa7-3cbabc49d50b\n",
            "Filename: 8.json\n",
            "Date: 2024-03-15\n",
            "Source: Log\n",
            "Category: log_data\n",
            "File Content: Access logs for March 2024.\n",
            "==================================================\n",
            "Document ID: ba7ab37f-3a78-47b2-a0a7-68d20ad8c49e\n",
            "Filename: 8.json\n",
            "Date: 2024-03-15\n",
            "Source: Log\n",
            "Category: log_data\n",
            "File Content: Access logs for March 2024.\n",
            "==================================================\n",
            "Document ID: 93369d1d-55df-42f9-8639-184407bc2508\n",
            "Filename: 4.json\n",
            "Date: 2024-02-28\n",
            "Source: Log\n",
            "Category: log_data\n",
            "File Content: Server logs for February 2024.\n",
            "==================================================\n",
            "Document ID: 056873b2-1de8-4908-8bea-a02ea609e6b3\n",
            "Filename: 4.json\n",
            "Date: 2024-02-28\n",
            "Source: Log\n",
            "Category: log_data\n",
            "File Content: Server logs for February 2024.\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vN-ztUvHrbuL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}